#!/usr/bin/env python3
"""
AGX Orin RealSense D435 RGBDé‡‡é›†ç«¯ - gRPC Client
é‡‡é›†D435çš„RGB+Depthç”»é¢ï¼Œé€šè¿‡gRPCå‘é€åˆ°äº‘ç«¯æ¨ç†
æ”¯æŒ HTTP è§†é¢‘æµç”¨äºè¿œç¨‹æŸ¥çœ‹ï¼ˆRGB + Depth colormapå¹¶æ’æ˜¾ç¤ºï¼‰

æœåŠ¡å™¨è¿”å›çš„æ˜¯ waypointsï¼ˆç´¯ç§¯ä½ç§»ï¼‰ï¼Œä¸æ˜¯é€Ÿåº¦ï¼
- x: å‰è¿›æ–¹å‘ä½ç§» (m)ï¼Œç›¸å¯¹èµ·ç‚¹
- y: å·¦å³æ–¹å‘ä½ç§» (m)ï¼Œç›¸å¯¹èµ·ç‚¹
- theta: æœå‘è§’ (rad)ï¼Œç›¸å¯¹èµ·ç‚¹
"""

import cv2
import grpc
import time
import argparse
import numpy as np
from typing import Optional, Tuple
from threading import Thread, Lock
import math

# RealSense
import pyrealsense2 as rs

# å¯¼å…¥ç”Ÿæˆçš„ gRPC ä»£ç 
import inference_pb2
import inference_pb2_grpc


class RGBDStreamer:
    """RealSense D435 RGBDé‡‡é›† + gRPC å®¢æˆ·ç«¯ + HTTP è§†é¢‘æµ"""
    
    def __init__(
        self,
        server_addr: str = "localhost:50051",
        width: int = 640,
        height: int = 480,
        fps: int = 15,
        jpeg_quality: int = 80,
        http_port: int = 8080,
        align_depth: bool = True,
    ):
        self.server_addr = server_addr
        self.width = width
        self.height = height
        self.fps = fps
        self.jpeg_quality = jpeg_quality
        self.http_port = http_port
        self.align_depth = align_depth
        
        self.channel = None
        self.stub = None
        self.pipeline = None
        self.config = None
        self.align = None
        self.depth_scale = 0.001  # D435é»˜è®¤depth scale
        self.frame_id = 0
        
        # HTTP æµç›¸å…³
        self._current_frame = None
        self._frame_lock = Lock()
        self._http_server = None
        
    def connect(self) -> bool:
        """è¿æ¥gRPCæœåŠ¡å™¨"""
        print(f"[RGBD] è¿æ¥æœåŠ¡å™¨: {self.server_addr}")
        
        self.channel = grpc.insecure_channel(
            self.server_addr,
            options=[
                ('grpc.max_send_message_length', 50 * 1024 * 1024),
                ('grpc.max_receive_message_length', 50 * 1024 * 1024),
            ]
        )
        self.stub = inference_pb2_grpc.InferenceServiceStub(self.channel)
        
        # å¥åº·æ£€æŸ¥
        try:
            response = self.stub.HealthCheck(inference_pb2.Empty())
            print(f"[RGBD] æœåŠ¡å™¨çŠ¶æ€: healthy={response.healthy}, device={response.device}")
            return response.healthy
        except grpc.RpcError as e:
            print(f"[RGBD] è¿æ¥å¤±è´¥: {e}")
            return False
    
    def open_camera(self) -> bool:
        """æ‰“å¼€RealSense D435"""
        print(f"[RGBD] åˆå§‹åŒ– RealSense D435...")
        
        try:
            # åˆ›å»ºpipelineå’Œconfig
            self.pipeline = rs.pipeline()
            self.config = rs.config()
            
            # æ£€æµ‹å¯ç”¨è®¾å¤‡
            ctx = rs.context()
            devices = ctx.query_devices()
            if len(devices) == 0:
                print("[RGBD] æœªæ£€æµ‹åˆ°RealSenseè®¾å¤‡!")
                return False
            
            device = devices[0]
            serial = device.get_info(rs.camera_info.serial_number)
            name = device.get_info(rs.camera_info.name)
            print(f"[RGBD] æ£€æµ‹åˆ°è®¾å¤‡: {name} (SN: {serial})")
            
            # é…ç½®RGBå’ŒDepthæµ
            self.config.enable_stream(rs.stream.color, self.width, self.height, rs.format.bgr8, self.fps)
            self.config.enable_stream(rs.stream.depth, self.width, self.height, rs.format.z16, self.fps)
            
            # å¯åŠ¨pipeline
            profile = self.pipeline.start(self.config)
            
            # è·å–æ·±åº¦æ¯”ä¾‹å› å­
            depth_sensor = profile.get_device().first_depth_sensor()
            self.depth_scale = depth_sensor.get_depth_scale()
            print(f"[RGBD] æ·±åº¦æ¯”ä¾‹å› å­: {self.depth_scale} (depth_value * scale = meters)")
            
            # åˆ›å»ºå¯¹é½å™¨ï¼ˆå°†æ·±åº¦å›¾å¯¹é½åˆ°RGBï¼‰
            if self.align_depth:
                self.align = rs.align(rs.stream.color)
                print("[RGBD] æ·±åº¦å›¾å¯¹é½åˆ°RGBå·²å¯ç”¨")
            
            # è·å–å®é™…å‚æ•°
            color_profile = profile.get_stream(rs.stream.color).as_video_stream_profile()
            depth_profile = profile.get_stream(rs.stream.depth).as_video_stream_profile()
            
            print(f"[RGBD] RGBæµ: {color_profile.width()}x{color_profile.height()} @ {color_profile.fps()}fps")
            print(f"[RGBD] Depthæµ: {depth_profile.width()}x{depth_profile.height()} @ {depth_profile.fps()}fps")
            
            # é¢„çƒ­ï¼ˆä¸¢å¼ƒå‰å‡ å¸§è®©è‡ªåŠ¨æ›å…‰ç¨³å®šï¼‰
            print("[RGBD] é¢„çƒ­ä¸­...")
            for _ in range(30):
                self.pipeline.wait_for_frames()
            print("[RGBD] é¢„çƒ­å®Œæˆ")
            
            return True
            
        except Exception as e:
            print(f"[RGBD] åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def get_frames(self) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:
        """è·å–å¯¹é½çš„RGBå’ŒDepthå¸§"""
        try:
            frames = self.pipeline.wait_for_frames(timeout_ms=1000)
            
            if self.align:
                frames = self.align.process(frames)
            
            color_frame = frames.get_color_frame()
            depth_frame = frames.get_depth_frame()
            
            if not color_frame or not depth_frame:
                return None, None
            
            color_image = np.asanyarray(color_frame.get_data())
            depth_image = np.asanyarray(depth_frame.get_data())
            
            return color_image, depth_image
            
        except Exception as e:
            print(f"[RGBD] è·å–å¸§å¤±è´¥: {e}")
            return None, None
    
    def encode_rgb(self, frame: np.ndarray) -> bytes:
        """JPEGç¼–ç RGBå›¾åƒ"""
        # BGR -> RGB for server
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        _, buffer = cv2.imencode('.jpg', rgb, [cv2.IMWRITE_JPEG_QUALITY, self.jpeg_quality])
        return buffer.tobytes()
    
    def encode_depth(self, depth: np.ndarray) -> bytes:
        """PNGç¼–ç æ·±åº¦å›¾ï¼ˆ16bitæ— æŸï¼‰"""
        _, buffer = cv2.imencode('.png', depth)
        return buffer.tobytes()
    
    def depth_to_colormap(self, depth: np.ndarray, max_depth_m: float = 5.0) -> np.ndarray:
        """å°†æ·±åº¦å›¾è½¬æ¢ä¸ºcolormapç”¨äºå¯è§†åŒ–"""
        # è½¬æ¢ä¸ºç±³
        depth_m = depth.astype(np.float32) * self.depth_scale
        # å½’ä¸€åŒ–åˆ°0-255
        depth_normalized = np.clip(depth_m / max_depth_m * 255, 0, 255).astype(np.uint8)
        # åº”ç”¨colormap
        colormap = cv2.applyColorMap(depth_normalized, cv2.COLORMAP_JET)
        return colormap
    
    def infer(self, color: np.ndarray, depth: np.ndarray, instruction: str) -> Tuple[Optional[np.ndarray], float]:
        """å‘é€RGBDå¸§åˆ°äº‘ç«¯æ¨ç†ï¼Œè¿”å› waypointsï¼ˆç´¯ç§¯ä½ç§»åºåˆ—ï¼‰"""
        self.frame_id += 1
        
        # ç¼–ç 
        image_data = self.encode_rgb(color)
        depth_data = self.encode_depth(depth)
        
        # å‘é€è¯·æ±‚
        request = inference_pb2.InferRequest(
            image_data=image_data,
            instruction=instruction,
            frame_id=self.frame_id,
            timestamp_ms=int(time.time() * 1000),
            depth_data=depth_data,
            depth_width=depth.shape[1],
            depth_height=depth.shape[0],
            depth_scale=self.depth_scale,
        )
        
        try:
            response = self.stub.Infer(request)
            
            if response.success:
                waypoints = np.array(response.waypoints).reshape(response.n_waypoints, 3)
                return waypoints, response.inference_time_ms
            else:
                print(f"[RGBD] æ¨ç†é”™è¯¯: {response.error}")
                return None, 0
        except grpc.RpcError as e:
            print(f"[RGBD] gRPCé”™è¯¯: {e}")
            return None, 0
    
    def draw_trajectory(self, frame: np.ndarray, waypoints: np.ndarray, scale: float = 120.0) -> np.ndarray:
        """åœ¨ç”»é¢ä¸Šç»˜åˆ¶è½¨è¿¹"""
        vis = frame.copy()
        h, w = vis.shape[:2]
        cx = w // 2
        cy = int(h * 0.86)
        
        arrow_len = 20
        
        points = [(cx, cy)]
        for i, (x, y, theta) in enumerate(waypoints):
            px = int(cx - y * scale)
            py = int(cy - x * scale)
            points.append((px, py))
            
            progress = i / max(len(waypoints) - 1, 1)
            color = (
                int(255 * progress),
                int(255 * (1 - progress)),
                0
            )
            cv2.circle(vis, (px, py), 5, color, -1)
            cv2.circle(vis, (px, py), 7, (255, 255, 255), 1)
            
            arrow_dx = int(-arrow_len * math.sin(theta))
            arrow_dy = int(-arrow_len * math.cos(theta))
            arrow_end = (px + arrow_dx, py + arrow_dy)
            
            turn_intensity = min(abs(theta) / 0.5, 1.0)
            arrow_color = (
                int(255 * turn_intensity),
                int(255 * (1 - turn_intensity * 0.5)),
                0
            )
            cv2.arrowedLine(vis, (px, py), arrow_end, arrow_color, 2, tipLength=0.4)
        
        for i in range(len(points) - 1):
            progress = i / max(len(points) - 2, 1)
            line_color = (
                int(100 * progress),
                int(200 * (1 - progress * 0.5)),
                0
            )
            cv2.line(vis, points[i], points[i + 1], line_color, 2)
        
        cv2.circle(vis, (cx, cy), 12, (255, 0, 0), -1)
        cv2.circle(vis, (cx, cy), 14, (255, 255, 255), 2)
        cv2.arrowedLine(vis, (cx, cy), (cx, cy - 35), (255, 100, 100), 3, tipLength=0.3)
        cv2.putText(vis, "Robot", (cx - 25, cy + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        if len(waypoints) > 0:
            x, y, theta = waypoints[0]
            wp_info = f"WP0: x={x:.2f}m y={y:.2f}m th={math.degrees(theta):.1f}deg"
            cv2.putText(vis, wp_info, (10, h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
        
        return vis
    
    def create_combined_view(self, color: np.ndarray, depth: np.ndarray, waypoints: Optional[np.ndarray] = None) -> np.ndarray:
        """åˆ›å»ºRGB + Depth colormapå¹¶æ’è§†å›¾"""
        # åœ¨RGBä¸Šç»˜åˆ¶è½¨è¿¹
        if waypoints is not None:
            color_vis = self.draw_trajectory(color, waypoints)
        else:
            color_vis = color.copy()
        
        # Depth colormap
        depth_colormap = self.depth_to_colormap(depth)
        
        # æ·»åŠ æ ‡ç­¾
        cv2.putText(color_vis, "RGB", (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        cv2.putText(depth_colormap, "Depth", (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # æ°´å¹³æ‹¼æ¥
        combined = np.hstack([color_vis, depth_colormap])
        
        return combined
    
    def _update_http_frame(self, frame: np.ndarray):
        """æ›´æ–° HTTP æµçš„å½“å‰å¸§"""
        with self._frame_lock:
            self._current_frame = frame.copy()
    
    def _generate_frames(self):
        """ç”Ÿæˆ MJPEG å¸§æµ"""
        while True:
            with self._frame_lock:
                if self._current_frame is None:
                    time.sleep(0.01)
                    continue
                frame = self._current_frame.copy()
            
            _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
            frame_bytes = buffer.tobytes()
            
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
            
            time.sleep(0.033)
    
    def _start_http_server(self):
        """å¯åŠ¨ HTTP è§†é¢‘æµæœåŠ¡å™¨"""
        try:
            from flask import Flask, Response
        except ImportError:
            print("[RGBD] è­¦å‘Š: Flask æœªå®‰è£…ï¼ŒHTTP æµåŠŸèƒ½ä¸å¯ç”¨")
            print("[RGBD] å®‰è£…: pip install flask")
            return
        
        app = Flask(__name__)
        streamer = self
        
        @app.route('/')
        def index():
            return '''
            <!DOCTYPE html>
            <html>
            <head>
                <title>RGBD Live Stream</title>
                <style>
                    * { margin: 0; padding: 0; box-sizing: border-box; }
                    body { 
                        background: linear-gradient(135deg, #0f0f23 0%, #1a1a3e 50%, #0f0f23 100%);
                        color: #e0e0ff; 
                        font-family: 'JetBrains Mono', 'Fira Code', monospace;
                        min-height: 100vh;
                        display: flex;
                        flex-direction: column;
                        align-items: center;
                        padding: 20px;
                    }
                    .header {
                        display: flex;
                        align-items: center;
                        gap: 15px;
                        margin-bottom: 20px;
                    }
                    h1 { 
                        color: #00ffaa;
                        font-size: 1.8em;
                        font-weight: 600;
                        text-shadow: 0 0 20px rgba(0, 255, 170, 0.3);
                    }
                    .status-badge {
                        background: linear-gradient(90deg, #00ff88, #00ccff);
                        color: #000;
                        padding: 5px 12px;
                        border-radius: 20px;
                        font-size: 0.75em;
                        font-weight: bold;
                        animation: pulse 2s infinite;
                    }
                    @keyframes pulse {
                        0%, 100% { opacity: 1; }
                        50% { opacity: 0.7; }
                    }
                    .video-container {
                        position: relative;
                        border: 3px solid #00ffaa;
                        border-radius: 12px;
                        overflow: hidden;
                        box-shadow: 0 0 40px rgba(0, 255, 170, 0.2);
                    }
                    img { 
                        display: block;
                        max-width: 100%;
                        height: auto;
                    }
                    .info-panel {
                        margin-top: 20px;
                        display: grid;
                        grid-template-columns: repeat(2, 1fr);
                        gap: 15px;
                        max-width: 800px;
                    }
                    .info-card {
                        background: rgba(255, 255, 255, 0.05);
                        border: 1px solid rgba(0, 255, 170, 0.3);
                        border-radius: 8px;
                        padding: 15px;
                    }
                    .info-card h3 {
                        color: #00ffaa;
                        font-size: 0.9em;
                        margin-bottom: 8px;
                    }
                    .info-card p {
                        color: #888;
                        font-size: 0.8em;
                        line-height: 1.6;
                    }
                    .legend {
                        margin-top: 15px;
                        padding: 15px;
                        background: rgba(255, 255, 255, 0.03);
                        border-radius: 8px;
                        font-size: 0.8em;
                        color: #aaa;
                        max-width: 800px;
                    }
                    .legend-item {
                        display: inline-block;
                        margin-right: 20px;
                    }
                    .legend-color {
                        display: inline-block;
                        width: 12px;
                        height: 12px;
                        border-radius: 50%;
                        margin-right: 5px;
                        vertical-align: middle;
                    }
                </style>
            </head>
            <body>
                <div class="header">
                    <h1>ğŸ“· RGBD Live Stream</h1>
                    <span class="status-badge">â— LIVE</span>
                </div>
                
                <div class="video-container">
                    <img src="/video_feed" alt="RGBD Stream">
                </div>
                
                <div class="info-panel">
                    <div class="info-card">
                        <h3>ğŸ¨ RGB View</h3>
                        <p>å·¦ä¾§æ˜¾ç¤ºRGBå½©è‰²å›¾åƒï¼Œå åŠ é¢„æµ‹è½¨è¿¹</p>
                    </div>
                    <div class="info-card">
                        <h3>ğŸ“ Depth View</h3>
                        <p>å³ä¾§æ˜¾ç¤ºæ·±åº¦å›¾colormap<br>
                        è“è‰²=è¿‘ â†’ çº¢è‰²=è¿œ</p>
                    </div>
                </div>
                
                <div class="legend">
                    <span class="legend-item"><span class="legend-color" style="background: #ff0000;"></span>æœºå™¨äººä½ç½®</span>
                    <span class="legend-item"><span class="legend-color" style="background: #00ff00;"></span>è¿‘å¤„waypoint</span>
                    <span class="legend-item"><span class="legend-color" style="background: #ff6600;"></span>è¿œå¤„waypoint</span>
                    <span class="legend-item">â¤ æœå‘ç®­å¤´</span>
                </div>
            </body>
            </html>
            '''
        
        @app.route('/video_feed')
        def video_feed():
            return Response(
                streamer._generate_frames(),
                mimetype='multipart/x-mixed-replace; boundary=frame'
            )
        
        import logging
        log = logging.getLogger('werkzeug')
        log.setLevel(logging.ERROR)
        
        print(f"[RGBD] HTTP è§†é¢‘æµå¯åŠ¨: http://0.0.0.0:{self.http_port}")
        app.run(host='0.0.0.0', port=self.http_port, threaded=True)
    
    def run(self, instruction: str = "Follow the person", display: bool = True, http_stream: bool = False, no_infer: bool = False):
        """ä¸»å¾ªç¯
        
        Args:
            instruction: æ¨ç†æŒ‡ä»¤
            display: æ˜¯å¦æœ¬åœ°æ˜¾ç¤º
            http_stream: æ˜¯å¦å¯ç”¨HTTPæµ
            no_infer: ä»…é¢„è§ˆæ¨¡å¼ï¼ˆä¸è¿æ¥æœåŠ¡å™¨ï¼‰
        """
        if not no_infer:
            if not self.connect():
                return
        else:
            print("[RGBD] é¢„è§ˆæ¨¡å¼ï¼šä¸è¿æ¥æ¨ç†æœåŠ¡å™¨")
        
        if not self.open_camera():
            return
        
        # å¯åŠ¨ HTTP æµæœåŠ¡å™¨
        if http_stream:
            http_thread = Thread(target=self._start_http_server, daemon=True)
            http_thread.start()
            time.sleep(1)
        
        print(f"[RGBD] å¼€å§‹{'æ¨ç†' if not no_infer else 'é¢„è§ˆ'}å¾ªç¯ï¼ŒæŒ‡ä»¤: '{instruction}'")
        if display:
            print("[RGBD] æŒ‰ 'q' é€€å‡º")
        else:
            print("[RGBD] æŒ‰ Ctrl+C é€€å‡º")
        
        frame_interval = 1.0 / self.fps
        last_time = time.time()
        
        try:
            while True:
                color, depth = self.get_frames()
                if color is None or depth is None:
                    continue
                
                # æ§åˆ¶å¸§ç‡
                current_time = time.time()
                if current_time - last_time < frame_interval:
                    continue
                last_time = current_time
                
                if no_infer:
                    # é¢„è§ˆæ¨¡å¼ï¼šåªæ˜¾ç¤ºRGB+Depth
                    vis = self.create_combined_view(color, depth, None)
                    info = f"Preview Mode | Frame: {self.frame_id}"
                    self.frame_id += 1
                else:
                    # æ¨ç†æ¨¡å¼
                    start = time.time()
                    result = self.infer(color, depth, instruction)
                    rtt = (time.time() - start) * 1000
                    
                    if result[0] is not None:
                        waypoints, server_time = result
                        vis = self.create_combined_view(color, depth, waypoints)
                        info = f"RTT: {rtt:.0f}ms | Server: {server_time:.0f}ms | Frame: {self.frame_id}"
                        
                        if not display:
                            x, y, theta = waypoints[0] if len(waypoints) > 0 else (0, 0, 0)
                            print(f"[RGBD] Frame {self.frame_id}: RTT={rtt:.0f}ms, x={x:.3f}m, y={y:.3f}m, theta={math.degrees(theta):.1f}deg")
                    else:
                        vis = self.create_combined_view(color, depth, None)
                        info = "Inference Failed"
                
                cv2.putText(vis, info, (10, vis.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                
                # æ›´æ–° HTTP æµ
                if http_stream:
                    self._update_http_frame(vis)
                
                # æœ¬åœ°æ˜¾ç¤º
                if display:
                    cv2.imshow('RGBD Streamer', vis)
                    key = cv2.waitKey(1) & 0xFF
                    if key == ord('q'):
                        break
                        
        except KeyboardInterrupt:
            print("\n[RGBD] æ”¶åˆ°ä¸­æ–­ä¿¡å·")
        finally:
            self.close(display)
    
    def close(self, display: bool = True):
        """æ¸…ç†èµ„æº"""
        if self.pipeline:
            self.pipeline.stop()
        if self.channel:
            self.channel.close()
        if display:
            cv2.destroyAllWindows()
        print("[RGBD] å·²å…³é—­")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='AGX Orin RealSense D435 RGBDé‡‡é›†ç«¯')
    parser.add_argument('--server', type=str, default='localhost:50051', help='gRPCæœåŠ¡å™¨åœ°å€')
    parser.add_argument('--width', type=int, default=640, help='å›¾åƒå®½åº¦')
    parser.add_argument('--height', type=int, default=480, help='å›¾åƒé«˜åº¦')
    parser.add_argument('--fps', type=int, default=15, help='ç›®æ ‡å¸§ç‡')
    parser.add_argument('--quality', type=int, default=80, help='JPEGè´¨é‡ (1-100)')
    parser.add_argument('--instruction', type=str, default='Follow the person', help='æ–‡æœ¬æŒ‡ä»¤')
    parser.add_argument('--no-display', action='store_true', help='ä¸æ˜¾ç¤ºç”»é¢ï¼ˆheadlessæ¨¡å¼ï¼‰')
    parser.add_argument('--http-stream', action='store_true', help='å¯ç”¨HTTPè§†é¢‘æµ')
    parser.add_argument('--http-port', type=int, default=8080, help='HTTPæµç«¯å£')
    parser.add_argument('--no-align', action='store_true', help='ä¸å¯¹é½æ·±åº¦å›¾åˆ°RGB')
    parser.add_argument('--no-infer', action='store_true', help='é¢„è§ˆæ¨¡å¼ï¼šä¸è¿æ¥æœåŠ¡å™¨')
    
    args = parser.parse_args()
    
    streamer = RGBDStreamer(
        server_addr=args.server,
        width=args.width,
        height=args.height,
        fps=args.fps,
        jpeg_quality=args.quality,
        http_port=args.http_port,
        align_depth=not args.no_align,
    )
    
    streamer.run(
        instruction=args.instruction, 
        display=not args.no_display,
        http_stream=args.http_stream,
        no_infer=args.no_infer,
    )

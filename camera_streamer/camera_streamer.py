#!/usr/bin/env python3
"""
AGX Orin æ‘„åƒå¤´é‡‡é›†ç«¯ - gRPC Client
é‡‡é›†USBæ‘„åƒå¤´ç”»é¢ï¼Œé€šè¿‡gRPCå‘é€åˆ°äº‘ç«¯æ¨ç†
æ”¯æŒ HTTP è§†é¢‘æµç”¨äºè¿œç¨‹æŸ¥çœ‹

æœåŠ¡å™¨è¿”å›çš„æ˜¯ waypointsï¼ˆç´¯ç§¯ä½ç§»ï¼‰ï¼Œä¸æ˜¯é€Ÿåº¦ï¼
- x: å‰è¿›æ–¹å‘ä½ç§» (m)ï¼Œç›¸å¯¹èµ·ç‚¹
- y: å·¦å³æ–¹å‘ä½ç§» (m)ï¼Œç›¸å¯¹èµ·ç‚¹
- theta: æœå‘è§’ (rad)ï¼Œç›¸å¯¹èµ·ç‚¹
"""

import cv2
import grpc
import time
import argparse
import numpy as np
from typing import Optional, Tuple
from threading import Thread, Lock
import math

# å¯¼å…¥ç”Ÿæˆçš„ gRPC ä»£ç 
import inference_pb2
import inference_pb2_grpc

# ROS2 å¯¼å…¥
try:
    import rclpy
    from rclpy.node import Node
    from std_msgs.msg import Float32MultiArray
    ROS2_AVAILABLE = True
except ImportError:
    ROS2_AVAILABLE = False
    print("[Client] è­¦å‘Š: ROS2 æœªå®‰è£…ï¼Œè¿åŠ¨æ§åˆ¶åŠŸèƒ½ä¸å¯ç”¨")
    print("[Client] å®‰è£…: sudo apt install ros-humble-rclpy ros-humble-std-msgs")


class MotionPublisher(Node):
    """ROS2 èŠ‚ç‚¹ï¼šå‘å¸ƒé€Ÿåº¦å‘½ä»¤åˆ° /motion_ref"""
    
    def __init__(self):
        super().__init__('intern_nav_motion_publisher')
        self._publisher = self.create_publisher(Float32MultiArray, '/motion_ref', 1)
        self._vel_cmd_lock = Lock()
        self._vel_cmd = [0.0, 0.0, 0.0]  # [linear_x, linear_y, angular_z]
        self._publish_rate = 50.0  # Hz
        self._timer = self.create_timer(1.0 / self._publish_rate, self._timer_callback)
        self.get_logger().info(f'MotionPublisher å·²å¯åŠ¨ï¼Œå‘å¸ƒé¢‘ç‡: {self._publish_rate}Hz')
    
    def update_velocity(self, linear_x: float, linear_y: float, angular_z: float):
        """æ›´æ–°é€Ÿåº¦å‘½ä»¤"""
        with self._vel_cmd_lock:
            self._vel_cmd = [linear_x, linear_y, angular_z]
    
    def _timer_callback(self):
        """å®šæ—¶å‘å¸ƒé€Ÿåº¦å‘½ä»¤"""
        with self._vel_cmd_lock:
            vel_cmd = self._vel_cmd.copy()
        
        msg = Float32MultiArray()
        msg.data = vel_cmd
        self._publisher.publish(msg)


class CameraStreamer:
    """æ‘„åƒå¤´é‡‡é›† + gRPC å®¢æˆ·ç«¯ + HTTP è§†é¢‘æµ"""
    
    def __init__(
        self,
        server_addr: str = "localhost:50051",
        camera_idx: int = 0,
        width: int = 640,
        height: int = 480,
        fps: int = 10,
        jpeg_quality: int = 80,
        http_port: int = 8080,
        enable_ros2: bool = True,
        vel_time_scale: float = 0.1
    ):
        self.server_addr = server_addr
        self.camera_idx = camera_idx
        self.width = width
        self.height = height
        self.fps = fps
        self.jpeg_quality = jpeg_quality
        self.http_port = http_port
        self.enable_ros2 = enable_ros2 and ROS2_AVAILABLE
        self.vel_time_scale = vel_time_scale  # waypointä½ç§»åˆ°é€Ÿåº¦çš„è½¬æ¢æ—¶é—´å°ºåº¦
        
        self.channel = None
        self.stub = None
        self.cap = None
        self.frame_id = 0
        
        # HTTP æµç›¸å…³
        self._current_frame = None
        self._frame_lock = Lock()
        self._http_server = None
        
        # ROS2 ç›¸å…³
        self._ros2_node = None
        self._ros2_thread = None
        self._rclpy_initialized = False
        
    def connect(self) -> bool:
        """è¿æ¥gRPCæœåŠ¡å™¨"""
        print(f"[Client] è¿æ¥æœåŠ¡å™¨: {self.server_addr}")
        
        self.channel = grpc.insecure_channel(
            self.server_addr,
            options=[
                ('grpc.max_send_message_length', 50 * 1024 * 1024),
                ('grpc.max_receive_message_length', 50 * 1024 * 1024),
            ]
        )
        self.stub = inference_pb2_grpc.InferenceServiceStub(self.channel)
        
        # å¥åº·æ£€æŸ¥
        try:
            response = self.stub.HealthCheck(inference_pb2.Empty())
            print(f"[Client] æœåŠ¡å™¨çŠ¶æ€: healthy={response.healthy}, device={response.device}")
            return response.healthy
        except grpc.RpcError as e:
            print(f"[Client] è¿æ¥å¤±è´¥: {e}")
            return False
    
    def open_camera(self) -> bool:
        """æ‰“å¼€æ‘„åƒå¤´"""
        print(f"[Client] æ‰“å¼€æ‘„åƒå¤´: {self.camera_idx}")
        
        self.cap = cv2.VideoCapture(self.camera_idx)
        if not self.cap.isOpened():
            print(f"[Client] æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {self.camera_idx}")
            return False
        
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.width)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.height)
        self.cap.set(cv2.CAP_PROP_FPS, self.fps)
        
        actual_w = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_h = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        actual_fps = self.cap.get(cv2.CAP_PROP_FPS)
        
        print(f"[Client] æ‘„åƒå¤´å‚æ•°: {actual_w}x{actual_h} @ {actual_fps}fps")
        return True
    
    def encode_frame(self, frame: np.ndarray) -> bytes:
        """JPEGç¼–ç """
        # BGR -> RGB
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        _, buffer = cv2.imencode('.jpg', rgb, [cv2.IMWRITE_JPEG_QUALITY, self.jpeg_quality])
        return buffer.tobytes()
    
    def infer(self, frame: np.ndarray, instruction: str) -> Tuple[Optional[np.ndarray], float]:
        """å‘é€å¸§åˆ°äº‘ç«¯æ¨ç†ï¼Œè¿”å› waypointsï¼ˆç´¯ç§¯ä½ç§»åºåˆ—ï¼‰"""
        self.frame_id += 1
        
        # ç¼–ç 
        image_data = self.encode_frame(frame)
        
        # å‘é€è¯·æ±‚
        request = inference_pb2.InferRequest(
            image_data=image_data,
            instruction=instruction,
            frame_id=self.frame_id,
            timestamp_ms=int(time.time() * 1000)
        )
        
        try:
            response = self.stub.Infer(request)
            
            if response.success:
                # è°ƒè¯•ï¼šæ‰“å°æ”¶åˆ°çš„åŸå§‹æ•°æ®
                print(f"[Client DEBUG] æ”¶åˆ°: n_waypoints={response.n_waypoints}, waypointsé•¿åº¦={len(response.waypoints)}, å‰9ä¸ªå€¼={list(response.waypoints[:9]) if len(response.waypoints) > 0 else []}")
                
                # æœåŠ¡å™¨è¿”å›çš„æ˜¯ç´¯ç§¯ä½ç§»: [x, y, theta] * n_waypoints
                if response.n_waypoints > 0 and len(response.waypoints) >= response.n_waypoints * 3:
                    waypoints = np.array(response.waypoints).reshape(response.n_waypoints, 3)
                else:
                    print(f"[Client] è­¦å‘Š: waypointsæ•°æ®å¼‚å¸¸ - n_waypoints={response.n_waypoints}, å®é™…é•¿åº¦={len(response.waypoints)}")
                    return None, 0
                return waypoints, response.inference_time_ms
            else:
                print(f"[Client] æ¨ç†é”™è¯¯: {response.error}")
                return None, 0
        except grpc.RpcError as e:
            print(f"[Client] gRPCé”™è¯¯: {e}")
            return None, 0
    
    def draw_trajectory(self, frame: np.ndarray, waypoints: np.ndarray, scale: float = 120.0) -> np.ndarray:
        """
        åœ¨ç”»é¢ä¸Šç»˜åˆ¶è½¨è¿¹
        
        å‚æ•°:
            frame: åŸå§‹å›¾åƒ
            waypoints: ç´¯ç§¯ä½ç§»åºåˆ— (N, 3) - [x, y, theta]
                       x: å‰è¿›æ–¹å‘ä½ç§» (m)
                       y: å·¦ä¾§æ–¹å‘ä½ç§» (m)
                       theta: æœå‘è§’ (rad)
            scale: åƒç´ /ç±³ çš„ç¼©æ”¾æ¯”ä¾‹ (é»˜è®¤120ï¼Œä¸é¡¹ç›®å…¶ä»–åœ°æ–¹ä¸€è‡´)
        """
        vis = frame.copy()
        h, w = vis.shape[:2]
        # ä¸é¡¹ç›®å…¶ä»–åœ°æ–¹ä¸€è‡´çš„æŠ•å½±å‚æ•°
        cx = w // 2              # å›¾åƒå®½åº¦ä¸­å¿ƒ
        cy = int(h * 0.86)       # å›¾åƒé«˜åº¦çš„ 86% å¤„ä½œä¸ºæœºå™¨äººä½ç½®
        
        arrow_len = 20  # æ–¹å‘ç®­å¤´é•¿åº¦
        
        # ç»˜åˆ¶è½¨è¿¹ç‚¹
        points = [(cx, cy)]  # èµ·ç‚¹
        for i, (x, y, theta) in enumerate(waypoints):
            # è½¬æ¢åˆ°å±å¹•åæ ‡
            # ä¸–ç•Œåæ ‡: x=å‰ï¼ˆå‘ä¸Šï¼‰ï¼Œy=å·¦ï¼ˆå‘å·¦ï¼‰
            # å±å¹•åæ ‡: pxå‘å³å¢åŠ ï¼Œpyå‘ä¸‹å¢åŠ 
            px = int(cx - y * scale)  # yå·¦ â†’ pxå·¦
            py = int(cy - x * scale)  # xå‰ â†’ pyä¸Š
            points.append((px, py))
            
            # ç”»ç‚¹
            # é¢œè‰²æ¸å˜ï¼šç»¿è‰²ï¼ˆè¿‘ï¼‰â†’ çº¢è‰²ï¼ˆè¿œï¼‰
            progress = i / max(len(waypoints) - 1, 1)
            color = (
                int(255 * progress),      # R: è¿œå¤„å˜çº¢
                int(255 * (1 - progress)), # G: è¿‘å¤„ç»¿
                0
            )
            cv2.circle(vis, (px, py), 5, color, -1)
            cv2.circle(vis, (px, py), 7, (255, 255, 255), 1)
            
            # ç”»æ–¹å‘ç®­å¤´ï¼ˆæ˜¾ç¤º thetaï¼‰
            arrow_dx = int(-arrow_len * math.sin(theta))
            arrow_dy = int(-arrow_len * math.cos(theta))
            arrow_end = (px + arrow_dx, py + arrow_dy)
            
            # ç®­å¤´é¢œè‰²ï¼šæ ¹æ®è½¬å‘è§’åº¦
            turn_intensity = min(abs(theta) / 0.5, 1.0)  # 0.5 rad â‰ˆ 30Â° ä½œä¸ºæœ€å¤§
            arrow_color = (
                int(255 * turn_intensity),
                int(255 * (1 - turn_intensity * 0.5)),
                0
            )
            cv2.arrowedLine(vis, (px, py), arrow_end, arrow_color, 2, tipLength=0.4)
        
        # è¿çº¿ï¼ˆè½¨è¿¹è·¯å¾„ï¼‰
        for i in range(len(points) - 1):
            # æ¸å˜çº¿æ¡é¢œè‰²
            progress = i / max(len(points) - 2, 1)
            line_color = (
                int(100 * progress),
                int(200 * (1 - progress * 0.5)),
                0
            )
            cv2.line(vis, points[i], points[i + 1], line_color, 2)
        
        # ç”»æœºå™¨äººä½ç½®ï¼ˆåº•éƒ¨ä¸­å¿ƒ = èµ·ç‚¹ï¼‰
        cv2.circle(vis, (cx, cy), 12, (255, 0, 0), -1)
        cv2.circle(vis, (cx, cy), 14, (255, 255, 255), 2)
        # æœºå™¨äººæœå‘ç®­å¤´ï¼ˆå‘ä¸Š = åˆå§‹æœå‘ï¼‰
        cv2.arrowedLine(vis, (cx, cy), (cx, cy - 35), (255, 100, 100), 3, tipLength=0.3)
        cv2.putText(vis, "Robot", (cx - 25, cy + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # æ˜¾ç¤ºç¬¬ä¸€ä¸ª waypoint ä¿¡æ¯
        if len(waypoints) > 0:
            x, y, theta = waypoints[0]
            wp_info = f"WP0: x={x:.2f}m y={y:.2f}m th={math.degrees(theta):.1f}deg"
            cv2.putText(vis, wp_info, (10, h - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
        
        return vis
    
    def _update_http_frame(self, frame: np.ndarray):
        """æ›´æ–° HTTP æµçš„å½“å‰å¸§"""
        with self._frame_lock:
            self._current_frame = frame.copy()
    
    def _generate_frames(self):
        """ç”Ÿæˆ MJPEG å¸§æµ"""
        while True:
            with self._frame_lock:
                if self._current_frame is None:
                    time.sleep(0.01)
                    continue
                frame = self._current_frame.copy()
            
            _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
            frame_bytes = buffer.tobytes()
            
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
            
            time.sleep(0.033)  # ~30fps
    
    def _start_http_server(self):
        """å¯åŠ¨ HTTP è§†é¢‘æµæœåŠ¡å™¨"""
        try:
            from flask import Flask, Response
        except ImportError:
            print("[Client] è­¦å‘Š: Flask æœªå®‰è£…ï¼ŒHTTP æµåŠŸèƒ½ä¸å¯ç”¨")
            print("[Client] å®‰è£…: pip install flask")
            return
        
        app = Flask(__name__)
        streamer = self
        
        @app.route('/')
        def index():
            return '''
            <!DOCTYPE html>
            <html>
            <head>
                <title>OpenTrackVLA Live Stream</title>
                <style>
                    body { 
                        background: #1a1a2e; 
                        color: #eee; 
                        font-family: monospace;
                        display: flex;
                        flex-direction: column;
                        align-items: center;
                        padding: 20px;
                    }
                    h1 { color: #00ff88; }
                    img { 
                        border: 2px solid #00ff88; 
                        border-radius: 8px;
                        max-width: 100%;
                    }
                    .info { 
                        margin-top: 10px; 
                        color: #888; 
                    }
                    .legend {
                        margin-top: 15px;
                        padding: 10px;
                        background: #2a2a4e;
                        border-radius: 5px;
                        font-size: 12px;
                    }
                </style>
            </head>
            <body>
                <h1>ğŸ¤– OpenTrackVLA Live Stream</h1>
                <img src="/video_feed" alt="Video Stream">
                <p class="info">å®æ—¶æ¨ç†å¯è§†åŒ– | ç´¯ç§¯ä½ç§»è½¨è¿¹</p>
                <div class="legend">
                    <b>å›¾ä¾‹:</b><br>
                    ğŸ”´ æœºå™¨äººä½ç½®ï¼ˆèµ·ç‚¹ï¼‰| 
                    ğŸŸ¢â†’ğŸ”´ waypointsï¼ˆè¿‘â†’è¿œï¼‰| 
                    â¤ æœå‘ç®­å¤´
                </div>
            </body>
            </html>
            '''
        
        @app.route('/video_feed')
        def video_feed():
            return Response(
                streamer._generate_frames(),
                mimetype='multipart/x-mixed-replace; boundary=frame'
            )
        
        import logging
        log = logging.getLogger('werkzeug')
        log.setLevel(logging.ERROR)
        
        print(f"[Client] HTTP è§†é¢‘æµå¯åŠ¨: http://0.0.0.0:{self.http_port}")
        app.run(host='0.0.0.0', port=self.http_port, threaded=True)
    
    def _ros2_spin_thread(self):
        """ROS2 spin çº¿ç¨‹"""
        try:
            rclpy.spin(self._ros2_node)
        except Exception as e:
            print(f"[Client] ROS2 spin é”™è¯¯: {e}")
        finally:
            if self._ros2_node:
                self._ros2_node.destroy_node()
            if self._rclpy_initialized:
                rclpy.shutdown()
    
    def run(self, instruction: str = "Follow the person", display: bool = True, http_stream: bool = False):
        """ä¸»å¾ªç¯"""
        if not self.connect():
            return
        
        if not self.open_camera():
            return
        
        # å¯åŠ¨ ROS2 èŠ‚ç‚¹
        if self.enable_ros2:
            try:
                if not self._rclpy_initialized:
                    rclpy.init()
                    self._rclpy_initialized = True
                self._ros2_node = MotionPublisher()
                self._ros2_thread = Thread(target=self._ros2_spin_thread, daemon=True)
                self._ros2_thread.start()
                print("[Client] ROS2 è¿åŠ¨æ§åˆ¶èŠ‚ç‚¹å·²å¯åŠ¨ï¼Œå‘å¸ƒåˆ° /motion_ref")
                time.sleep(0.5)  # ç­‰å¾…èŠ‚ç‚¹åˆå§‹åŒ–
            except Exception as e:
                print(f"[Client] ROS2 å¯åŠ¨å¤±è´¥: {e}")
                self.enable_ros2 = False
        
        # å¯åŠ¨ HTTP æµæœåŠ¡å™¨
        if http_stream:
            http_thread = Thread(target=self._start_http_server, daemon=True)
            http_thread.start()
            time.sleep(1)  # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
        
        print(f"[Client] å¼€å§‹æ¨ç†å¾ªç¯ï¼ŒæŒ‡ä»¤: '{instruction}'")
        if display:
            print("[Client] æŒ‰ 'q' é€€å‡º, 'r' é‡ç½®å†å²")
        else:
            print("[Client] æŒ‰ Ctrl+C é€€å‡º")
        
        frame_interval = 1.0 / self.fps
        last_time = time.time()
        
        try:
            while True:
                ret, frame = self.cap.read()
                if not ret:
                    print("[Client] è¯»å–å¸§å¤±è´¥")
                    continue
                
                # æ§åˆ¶å¸§ç‡
                current_time = time.time()
                if current_time - last_time < frame_interval:
                    continue
                last_time = current_time
                
                # æ¨ç†
                start = time.time()
                result = self.infer(frame, instruction)
                rtt = (time.time() - start) * 1000
                
                if result[0] is not None:
                    waypoints, server_time = result
                    vis = self.draw_trajectory(frame, waypoints)
                    
                    # å‘å¸ƒé€Ÿåº¦å‘½ä»¤åˆ° ROS2
                    # æ³¨æ„ï¼šä½¿ç”¨ waypoints[1]ï¼ˆç¬¬ 2 ä¸ª waypointï¼‰ï¼Œä¸ trained_agent.py çš„ _planner_action ä¸€è‡´
                    if self.enable_ros2 and self._ros2_node is not None and len(waypoints) > 1:
                        x, y, theta = waypoints[1]
                        # waypoints æ˜¯ç´¯ç§¯ä½ç§»ï¼Œè½¬æ¢ä¸ºé€Ÿåº¦ï¼šé€Ÿåº¦ = ä½ç§» / æ—¶é—´å°ºåº¦
                        # dt = 0.1 ç§’ï¼Œä¸ trained_agent.py ä¸­çš„ dt ä¸€è‡´
                        linear_x = x / self.vel_time_scale
                        linear_y = y / self.vel_time_scale
                        angular_z = theta / self.vel_time_scale
                        self._ros2_node.update_velocity(linear_x, linear_y, angular_z)
                    
                    # æ˜¾ç¤ºä¿¡æ¯
                    info = f"RTT: {rtt:.0f}ms | Server: {server_time:.0f}ms | Frame: {self.frame_id}"
                    cv2.putText(vis, info, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    
                    # ç»ˆç«¯è¾“å‡º
                    if not display:
                        x, y, theta = waypoints[0] if len(waypoints) > 0 else (0, 0, 0)
                        print(f"[Client] Frame {self.frame_id}: RTT={rtt:.0f}ms, x={x:.3f}m, y={y:.3f}m, theta={math.degrees(theta):.1f}deg")
                else:
                    vis = frame
                    cv2.putText(vis, "Inference Failed", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                
                # æ›´æ–° HTTP æµ
                if http_stream:
                    self._update_http_frame(vis)
                
                # æœ¬åœ°æ˜¾ç¤º
                if display:
                    cv2.imshow('OpenTrackVLA Streamer', vis)
                    key = cv2.waitKey(1) & 0xFF
                    if key == ord('q'):
                        break
                    elif key == ord('r'):
                        print("[Client] å‘é€é‡ç½®è¯·æ±‚...")
                        
        except KeyboardInterrupt:
            print("\n[Client] æ”¶åˆ°ä¸­æ–­ä¿¡å·")
        finally:
            self.close(display)
    
    def close(self, display: bool = True):
        """æ¸…ç†èµ„æº"""
        # åœæ­¢é€Ÿåº¦å‘½ä»¤ï¼ˆå‘é€é›¶é€Ÿåº¦ï¼‰
        if self.enable_ros2 and self._ros2_node is not None:
            self._ros2_node.update_velocity(0.0, 0.0, 0.0)
            time.sleep(0.1)  # ç¡®ä¿æœ€åä¸€æ¡æ¶ˆæ¯å‘é€
        
        if self.cap:
            self.cap.release()
        if self.channel:
            self.channel.close()
        # åªæœ‰åœ¨æ˜¾ç¤ºæ¨¡å¼ä¸‹æ‰è°ƒç”¨ destroyAllWindows
        if display:
            cv2.destroyAllWindows()
        print("[Client] å·²å…³é—­")


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='AGX Orin æ‘„åƒå¤´é‡‡é›†ç«¯')
    parser.add_argument('--server', type=str, default='localhost:50100', help='gRPCæœåŠ¡å™¨åœ°å€')
    parser.add_argument('--camera', type=int, default=0, help='æ‘„åƒå¤´ç´¢å¼•')
    parser.add_argument('--width', type=int, default=640, help='å›¾åƒå®½åº¦')
    parser.add_argument('--height', type=int, default=480, help='å›¾åƒé«˜åº¦')
    parser.add_argument('--fps', type=int, default=10, help='ç›®æ ‡å¸§ç‡')
    parser.add_argument('--quality', type=int, default=80, help='JPEGè´¨é‡ (1-100)')
    parser.add_argument('--instruction', type=str, default='Follow the person', help='æ–‡æœ¬æŒ‡ä»¤')
    parser.add_argument('--no-display', action='store_true', help='ä¸æ˜¾ç¤ºç”»é¢ï¼ˆheadlessæ¨¡å¼ï¼‰')
    parser.add_argument('--http-stream', action='store_true', help='å¯ç”¨HTTPè§†é¢‘æµï¼ˆç”¨äºè¿œç¨‹æŸ¥çœ‹ï¼‰')
    parser.add_argument('--http-port', type=int, default=8080, help='HTTPæµç«¯å£')
    parser.add_argument('--no-ros2', action='store_true', help='ç¦ç”¨ROS2è¿åŠ¨æ§åˆ¶')
    parser.add_argument('--vel-time-scale', type=float, default=0.1, help='waypointä½ç§»åˆ°é€Ÿåº¦çš„è½¬æ¢æ—¶é—´å°ºåº¦ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤0.1ç§’ä¸trained_agent.pyä¸€è‡´')
    
    args = parser.parse_args()
    
    streamer = CameraStreamer(
        server_addr=args.server,
        camera_idx=args.camera,
        width=args.width,
        height=args.height,
        fps=args.fps,
        jpeg_quality=args.quality,
        http_port=args.http_port,
        enable_ros2=not args.no_ros2,
        vel_time_scale=args.vel_time_scale
    )
    
    streamer.run(
        instruction=args.instruction, 
        display=not args.no_display,
        http_stream=args.http_stream
    )
